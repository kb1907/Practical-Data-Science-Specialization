# Practical Data Science on the AWS Cloud Specialization

This folder contains [Practical Data Science on the AWS Cloud Specialization](https://www.coursera.org/specializations/practical-data-science?) projects and notes.


----------------------------------------
<img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png" width="300" height="300">, <img src="https://github.com/kb1907/Practical-Data-Science-Specialization/assets/51021282/6b9da93c-ae7d-485a-8a45-6fde356deeda" width="300" height="300">

## WHAT  I LEARNED
------------------------
- I learned foundational concepts for exploratory data analysis (EDA), automated machine learning (AutoML), and text classification algorithms. 
- With Amazon SageMaker Clarify and Amazon SageMaker Data Wrangler, I analyzed a dataset for statistical bias, transformed the dataset into machine-readable features, and selected the most important features to train a multi-class text classifier.
- I performed automated machine learning (AutoML) to train, tune, and deploy the best text-classification algorithm for the given dataset using Amazon SageMaker Autopilot.
- I worked with Amazon SageMaker BlazingText, a highly optimized and scalable implementation of the popular FastText algorithm, to train a text classifier with very little code.


## There are 3 Courses in this Specialization
--------------------------------------------------

## [Course 1 - Analyze Datasets and Train ML Models using AutoML](https://github.com/kb1907/Practical-Data-Science-Specialization/tree/main/Analyze%20Datasets%20AutoML)

- [In the first course of the Practical Data Science Specialization](https://www.coursera.org/learn/automl-datasets-ml-models), 

- I learned foundational concepts for exploratory data analysis (EDA), automated machine learning (AutoML), and text classification algorithms. 
- With Amazon SageMaker Clarify and Amazon SageMaker Data Wrangler, I analyzed a dataset for statistical bias, transform the dataset into machine-readable features, and select the most important features to train a multi-class text classifier.
- I performed automated machine learning (AutoML) to automatically train, tune, and deploy the best text-classification algorithm for the given dataset using Amazon SageMaker Autopilot.
- I worked with Amazon SageMaker BlazingText, a highly optimized and scalable implementation of the popular FastText algorithm, to train a text classifier with very little code.


**Projects**
--------------
- [AWS Data Wrangler - Register and visualize dataset](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week1/C1_W1_Assignment_Learner.ipynb)
- [Detect Data Bias with Amazon SageMaker Clarify](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week2/C1_W2_Assignment_Detect_data_bias_with_Amazon_SageMaker_Clarify.ipynb)
- [Train a Model with Amazon SageMaker Autopilot](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week3/C1_W3_Assignment.ipynb)
- [Train a Text Classifier using Amazon SageMaker BlazingText built-in algorithm](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Analyze%20Datasets%20AutoML/Week4/C1_W4_Assignment.ipynb)




--------------------------------------------------

## [Course 2 - Build, Train, and Deploy ML Pipelines using BERT](https://github.com/kb1907/Practical-Data-Science-Specialization/tree/main/Build%20Train%20and%20Deploy%20ML%20Pipelines%20using%20BERT)

- [In the second course of the Practical Data Science Specialization](https://www.coursera.org/learn/ml-pipelines-bert?specialization=practical-data-science), 

- I learned to automate a natural language processing task by building an end-to-end machine learning pipeline using Hugging Faceâ€™s highly-optimized implementation of the state-of-the-art BERT algorithm with Amazon SageMaker Pipelines. 
     - Pipeline first transformed the dataset into BERT-readable features and stored the features in the Amazon SageMaker Feature Store.
     -  It then fine-tuned a text classification model to the dataset using a Hugging Face pre-trained model, which has learned to understand the human language from millions of Wikipedia documents.
     -  Finally, pipeline  evaluated the modelâ€™s accuracy and only deployed the model if the accuracy exceeds a given threshold. 
- I stored and managed machine learning features using a feature store.
- I debug, profiled, tuned and evaluated models while tracking data lineage and model artifacts.

  

**Projects**
--------------
- [Feature transformation with Amazon SageMaker processing job and Feature Store](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Build%20Train%20and%20Deploy%20ML%20Pipelines%20using%20BERT/Week1/C2_W1_Assignment.ipynb)
- [Train a review classifier with BERT and Amazon SageMaker](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Build%20Train%20and%20Deploy%20ML%20Pipelines%20using%20BERT/Week2/C2_W2_Assignment.ipynb)

--------------------------------------


## [Course 3 - Optimize ML Models and Deploy Human-in-the-Loop Pipelines](https://github.com/kb1907/Practical-Data-Science-Specialization/tree/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines)

- [In the third course of the Practical Data Science Specialization](https://www.coursera.org/learn/ml-models-human-in-the-loop-pipelines?specialization=practical-data-science), 

- I learned a series of performance-improvement and cost-reduction techniques to automatically tune model accuracy, compare prediction performance, and generate new training data with human intelligence.  
- After tuning text classifier using Amazon SageMaker Hyper-parameter Tuning (HPT), I deployed two model candidates into an A/B test to compare their real-time prediction performance and automatically scale the winning model using Amazon SageMaker Hosting. 
- Lastly, I set up a human-in-the-loop pipeline to fix misclassified predictions and generate new training data using Amazon Augmented AI and Amazon SageMaker Ground Truth.


  

**Projects**
--------------
- [Optimize models using Automatic Model Tuning](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week1/C3_W1_Assignment.ipynb)
- [A/B testing, traffic shifting and autoscaling](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week2/C3_W2_Assignment.ipynb)
-  [Data labeling and human-in-the-loop pipelines with Amazon Augmented AI (A2I)](https://github.com/kb1907/Practical-Data-Science-Specialization/blob/main/Optimize%20ML%20Models%20and%20Deploy%20Human-in-the-Loop%20Pipelines/Week3/C3_W3_Assignment.ipynb)



------------------------------------------------

### Disclaimer
------------------------------------
- **DeepLearning.AI** makes course notes available for educational purposes. 
- Project solutions are just for educational purposes. I highly recommend trying and solving project/program assignments on your own.

All the best ðŸ¤˜





  
